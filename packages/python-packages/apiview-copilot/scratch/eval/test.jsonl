{"response":"{\"comments\": [{\"rule_ids\": [\"python_design.html#python-client-connection-string\"], \"line_no\": 10, \"bad_code\": \"connection_string: Optional[str] = None,\", \"suggestion\": \"Remove the connection_string parameter from the __init__ method and instead implement a separate from_connection_string class method.\", \"comment\": \"The constructor should not accept a connection string per the guideline. Instead, a factory method (from_connection_string) must be provided if supported.\", \"source\": \"guideline\"}, {\"rule_ids\": [], \"line_no\": 171, \"bad_code\": \"ivar list: List[DenseCaption]\", \"suggestion\": \"ivar captions: List[DenseCaption]\", \"comment\": \"Using 'list' as an attribute name shadows the built-in list type and may be ambiguous. A more descriptive name such as 'captions' would better convey its intent.\", \"source\": \"generic\"}, {\"rule_ids\": [\"python_design.html#python-models-async\"], \"line_no\": 382, \"bad_code\": \"class azure.ai.vision.imageanalysis.models.aio.PeopleResult(MutableMapping[str, Any]):\", \"suggestion\": \"Remove PeopleResult from the aio sub-namespace and define it only once in the shared models namespace.\", \"comment\": \"Models should not be duplicated between the root and aio namespace per the guidelines. Reuse the model from azure.ai.vision.imageanalysis.models.\", \"source\": \"guideline\"}]}","query":"# Package is parsed using apiview-stub-generator(version:0.3.14), Python version: 3.12.9\n\nnamespace azure.ai.vision.imageanalysis\n\nclass azure.ai.vision.imageanalysis.ImageAnalysisClient(ImageAnalysisClient): implements ContextManager \n    def __init__(\n        self, \n        endpoint: str, \n        credential: Union[AzureKeyCredential, TokenCredential], \n        connection_string: Optional[str] = None,\n        *, \n        api_version: str = ..., \n        **kwargs: Any\n    ) -> None\n\n    @distributed_trace\n    def analyze(\n        self, \n        image_data: bytes, \n        visual_features: List[VisualFeatures], \n        *, \n        gender_neutral_caption: Optional[bool] = ..., \n        language: Optional[str] = ..., \n        model_version: Optional[str] = ..., \n        smart_crops_aspect_ratios: Optional[List[float]] = ..., \n        **kwargs: Any\n    ) -> ImageAnalysisResult\n\n    @distributed_trace\n    def analyze_from_url(\n        self, \n        image_url: str, \n        visual_features: List[VisualFeatures], \n        *, \n        gender_neutral_caption: Optional[bool] = ..., \n        language: Optional[str] = ..., \n        model_version: Optional[str] = ..., \n        smart_crops_aspect_ratios: Optional[List[float]] = ..., \n        **kwargs: Any\n    ) -> ImageAnalysisResult\n\n    def close(self) -> None\n\n    def send_request(\n        self, \n        request: HttpRequest, \n        *, \n        stream: bool = False, \n        **kwargs: Any\n    ) -> HttpResponse\n\nnamespace azure.ai.vision.imageanalysis.aio\n\nclass azure.ai.vision.imageanalysis.aio.ImageAnalysisClient(ImageAnalysisClient): implements AsyncContextManager \n    def __init__(\n        self, \n        endpoint: str, \n        credential: Union[AzureKeyCredential, AsyncTokenCredential], \n        *, \n        api_version: str = ..., \n        **kwargs: Any\n    ) -> None\n\n    @distributed_trace_async\n    async def analyze(\n        self, \n        image_data: bytes, \n        visual_features: List[VisualFeatures], \n        *, \n        gender_neutral_caption: Optional[bool] = ..., \n        language: Optional[str] = ..., \n        model_version: Optional[str] = ..., \n        smart_crops_aspect_ratios: Optional[List[float]] = ..., \n        **kwargs: Any\n    ) -> ImageAnalysisResult\n\n    @distributed_trace_async\n    async def analyze_from_url(\n        self, \n        image_url: str, \n        visual_features: List[VisualFeatures], \n        *, \n        gender_neutral_caption: Optional[bool] = ..., \n        language: Optional[str] = ..., \n        model_version: Optional[str] = ..., \n        smart_crops_aspect_ratios: Optional[List[float]] = ..., \n        **kwargs: Any\n    ) -> ImageAnalysisResult\n\n    async def close(self) -> None\n\n    def send_request(\n        self, \n        request: HttpRequest, \n        *, \n        stream: bool = False, \n        **kwargs: Any\n    ) -> Awaitable[AsyncHttpResponse]\n\nnamespace azure.ai.vision.imageanalysis.models\n\nclass azure.ai.vision.imageanalysis.models.CaptionResult(MutableMapping[str, Any]):\n    ivar confidence: float\n    ivar text: str\n\n    @overload\n    def __init__(\n        self, \n        *, \n        confidence: float, \n        text: str\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nclass azure.ai.vision.imageanalysis.models.CropRegion(MutableMapping[str, Any]):\n    ivar aspect_ratio: float\n    ivar bounding_box: ImageBoundingBox\n\n    @overload\n    def __init__(\n        self, \n        *, \n        aspect_ratio: float, \n        bounding_box: ImageBoundingBox\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nnamespace azure.ai.vision.imageanalysis.models\n\nclass azure.ai.vision.imageanalysis.models.DenseCaption(MutableMapping[str, Any]):\n    ivar bounding_box: ImageBoundingBox\n    ivar confidence: float\n    ivar text: str\n\n    @overload\n    def __init__(\n        self, \n        *, \n        bounding_box: ImageBoundingBox, \n        confidence: float, \n        text: str\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.DenseCaptionsResult(MutableMapping[str, Any]):\n    ivar list: List[DenseCaption]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        list: List[DenseCaption]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.DetectedTextBlock(MutableMapping[str, Any]):\n    ivar lines: List[DetectedTextLine]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        lines: List[DetectedTextLine]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nclass azure.ai.vision.imageanalysis.models.DetectedTextLine(MutableMapping[str, Any]):\n    ivar bounding_polygon: List[ImagePoint]\n    ivar text: str\n    ivar words: List[DetectedTextWord]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        bounding_polygon: List[ImagePoint], \n        text: str, \n        words: List[DetectedTextWord]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.DetectedTextWord(MutableMapping[str, Any]):\n    ivar bounding_polygon: List[ImagePoint]\n    ivar confidence: float\n    ivar text: str\n\n    @overload\n    def __init__(\n        self, \n        *, \n        bounding_polygon: List[ImagePoint], \n        confidence: float, \n        text: str\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.ImageAnalysisResult(MutableMapping[str, Any]):\n    ivar caption: Optional[CaptionResult]\n    ivar dense_captions: Optional[DenseCaptionsResult]\n    ivar metadata: ImageMetadata\n    ivar model_version: str\n    ivar objects: Optional[ObjectsResult]\n    ivar people: Optional[PeopleResult]\n    ivar read: Optional[ReadResult]\n    ivar smart_crops: Optional[SmartCropsResult]\n    ivar tags: Optional[TagsResult]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        caption: Optional[CaptionResult] = ..., \n        dense_captions: Optional[DenseCaptionsResult] = ..., \n        metadata: ImageMetadata, \n        model_version: str, \n        objects: Optional[ObjectsResult] = ..., \n        people: Optional[PeopleResult] = ..., \n        read: Optional[ReadResult] = ..., \n        smart_crops: Optional[SmartCropsResult] = ..., \n        tags: Optional[TagsResult] = ...\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.ImageBoundingBox(MutableMapping[str, Any]):\n    ivar height: int\n    ivar width: int\n    ivar x: int\n    ivar y: int\n\n    @overload\n    def __init__(\n        self, \n        *, \n        height: int, \n        width: int, \n        x: int, \n        y: int\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nclass azure.ai.vision.imageanalysis.models.ImageMetadata(MutableMapping[str, Any]):\n    ivar height: int\n    ivar width: int\n\n    @overload\n    def __init__(\n        self, \n        *, \n        height: int, \n        width: int\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.ImagePoint(MutableMapping[str, Any]):\n    ivar x: int\n    ivar y: int\n\n    @overload\n    def __init__(\n        self, \n        *, \n        x: int, \n        y: int\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.ObjectsResult(MutableMapping[str, Any]):\n    ivar list: List[DetectedObject]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        list: List[DetectedObject]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.aio.PeopleResult(MutableMapping[str, Any]):\n    ivar list: List[DetectedPerson]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        list: List[DetectedPerson]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.ReadResult(MutableMapping[str, Any]):\n    ivar blocks: List[DetectedTextBlock]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        blocks: List[DetectedTextBlock]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.SmartCropsResult(MutableMapping[str, Any]):\n    ivar list: List[CropRegion]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        list: List[CropRegion]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nclass azure.ai.vision.imageanalysis.models.TagsResult(MutableMapping[str, Any]):\n    ivar list: List[DetectedTag]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        list: List[DetectedTag]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nclass azure.ai.vision.imageanalysis.models.VisualFeatures(str, Enum):\n    CAPTION = 'caption'\n    DENSE_CAPTIONS = 'denseCaptions'\n    OBJECTS = 'objects'\n    PEOPLE = 'people'\n    READ = 'read'\n    SMART_CROPS = 'smartCrops'\n    TAGS = 'tags'","language":"python","actual":"{\"comments\":[{\"rule_ids\":[],\"line_no\":1,\"bad_code\":\"\",\"suggestion\":null,\"comment\":\"### API Summary\\n\\n**Purpose**\\nThis API provides image analysis capabilities for extracting insights from images supplied as binary data or via URL. It supports captioning, dense captioning, object and people detection, text extraction, smart crop generation, and tagging, with options for language selection, model version control, and formatting preferences for generated captions.\\n\\n**API Version**\\nVersioning is controlled via the `api_version` parameter on the clients, with the latest version used by default when not specified.\\n\\n**Client Classes**\\nThis API exposes synchronous `ImageAnalysisClient` and asynchronous `ImageAnalysisClient` in separate namespaces with equivalent functionality for image analysis workflows. The synchronous client additionally supports initialization using a connection string.\\n\\n**Functional Overview**\\nThe clients authenticate using either key-based or token-based credentials against a specified endpoint and provide operations to analyze images from in-memory data or remote URLs. Callers select which visual features to compute and can supply options such as preferred language, model version, smart-crop aspect ratios, and caption formatting. Results include consolidated analysis covering captions, dense captions, detected objects and people, recognized text, smart crop regions, tags, and image metadata. Both clients support context management for lifecycle handling and offer a pass-through to issue custom HTTP requests for advanced scenarios.\",\"source\":\"summary\"},{\"rule_ids\":[],\"line_no\":8,\"bad_code\":\"        endpoint: str, \",\"suggestion\":\"        endpoint: Optional[str] = None, \",\"comment\":\"Endpoint should be optional when a connection string is provided; make it Optional and validate mutual exclusivity.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":9,\"bad_code\":\"        credential: Union[AzureKeyCredential, TokenCredential], \",\"suggestion\":\"        credential: Optional[Union[AzureKeyCredential, TokenCredential]] = None, \",\"comment\":\"Credential should be optional when using a connection string; enforce one of connection string or credential.\",\"source\":\"generic\"},{\"rule_ids\":[\"python_design.html#python-client-connection-string\"],\"line_no\":10,\"bad_code\":\"        connection_string: Optional[str] = None,\",\"suggestion\":null,\"comment\":\"Remove the connection string parameter from the constructor. If connection strings are supported, expose a from_connection_string factory method. Ensure construction paths are unambiguous by making remaining parameters keyword-only and mutually exclusive where applicable.\",\"source\":\"merged\"},{\"rule_ids\":[],\"line_no\":19,\"bad_code\":\"        image_data: bytes, \",\"suggestion\":\"        image_data: Union[bytes, IO[bytes]], \",\"comment\":\"Allow file-like byte streams to avoid forcing callers to load entire images into memory.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":20,\"bad_code\":\"        visual_features: List[VisualFeatures], \",\"suggestion\":\"        visual_features: Iterable[VisualFeatures], \",\"comment\":\"Accept any iterable to improve flexibility and avoid forcing list materialization.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":30,\"bad_code\":\"    def analyze_from_url(\",\"suggestion\":null,\"comment\":\"Combine with analyze via overloads or a single image parameter that accepts bytes, file-like, or URL string to reduce duplication and improve discoverability.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":33,\"bad_code\":\"        visual_features: List[VisualFeatures], \",\"suggestion\":\"        visual_features: Iterable[VisualFeatures], \",\"comment\":\"Accept any iterable to improve flexibility and avoid forcing list materialization.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":67,\"bad_code\":\"        image_data: bytes, \",\"suggestion\":\"        image_data: Union[bytes, IO[bytes]], \",\"comment\":\"Allow file-like byte streams to avoid forcing callers to load entire images into memory.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":68,\"bad_code\":\"        visual_features: List[VisualFeatures], \",\"suggestion\":\"        visual_features: Iterable[VisualFeatures], \",\"comment\":\"Accept any iterable to improve flexibility and avoid forcing list materialization.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":81,\"bad_code\":\"        visual_features: List[VisualFeatures], \",\"suggestion\":\"        visual_features: Iterable[VisualFeatures], \",\"comment\":\"Accept any iterable to improve flexibility and avoid forcing list materialization.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":171,\"bad_code\":\"    ivar list: List[DenseCaption]\",\"suggestion\":\"    ivar captions: List[DenseCaption]\",\"comment\":\"Avoid using the built-in name 'list' as an attribute; use a descriptive, domain-specific name.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":177,\"bad_code\":\"        list: List[DenseCaption]\",\"suggestion\":\"        captions: List[DenseCaption]\",\"comment\":\"Avoid using the built-in name 'list' as a parameter; use a descriptive, domain-specific name.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":363,\"bad_code\":\"    ivar list: List[DetectedObject]\",\"suggestion\":\"    ivar objects: List[DetectedObject]\",\"comment\":\"Avoid using the built-in name 'list' as an attribute; use a descriptive, domain-specific name.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":369,\"bad_code\":\"        list: List[DetectedObject]\",\"suggestion\":\"        objects: List[DetectedObject]\",\"comment\":\"Avoid using the built-in name 'list' as a parameter; use a descriptive, domain-specific name.\",\"source\":\"generic\"},{\"rule_ids\":[\"python_design.html#python-models-async\"],\"line_no\":382,\"bad_code\":\"class azure.ai.vision.imageanalysis.models.aio.PeopleResult(MutableMapping[str, Any]):\",\"suggestion\":\"class azure.ai.vision.imageanalysis.models.PeopleResult(MutableMapping[str, Any]):\",\"comment\":\"This model is incorrectly placed under the async namespace; models should live under the shared models namespace for both sync and async to ensure consistency.\",\"source\":\"merged\"},{\"rule_ids\":[],\"line_no\":383,\"bad_code\":\"    ivar list: List[DetectedPerson]\",\"suggestion\":\"    ivar people: List[DetectedPerson]\",\"comment\":\"Avoid using the built-in name 'list' as an attribute; use a descriptive, domain-specific name.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":389,\"bad_code\":\"        list: List[DetectedPerson]\",\"suggestion\":\"        people: List[DetectedPerson]\",\"comment\":\"Avoid using the built-in name 'list' as a parameter; use a descriptive, domain-specific name.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":423,\"bad_code\":\"    ivar list: List[CropRegion]\",\"suggestion\":\"    ivar crops: List[CropRegion]\",\"comment\":\"Avoid using the built-in name 'list' as an attribute; use a descriptive, domain-specific name.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":429,\"bad_code\":\"        list: List[CropRegion]\",\"suggestion\":\"        crops: List[CropRegion]\",\"comment\":\"Avoid using the built-in name 'list' as a parameter; use a descriptive, domain-specific name.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":442,\"bad_code\":\"    ivar list: List[DetectedTag]\",\"suggestion\":\"    ivar tags: List[DetectedTag]\",\"comment\":\"Avoid using the built-in name 'list' as an attribute; use a descriptive, domain-specific name.\",\"source\":\"generic\"},{\"rule_ids\":[],\"line_no\":448,\"bad_code\":\"        list: List[DetectedTag]\",\"suggestion\":\"        tags: List[DetectedTag]\",\"comment\":\"Avoid using the built-in name 'list' as a parameter; use a descriptive, domain-specific name.\",\"source\":\"generic\"},{\"rule_ids\":[\"python_implementation.html#python-models-repr-length\"],\"line_no\":460,\"bad_code\":\"class azure.ai.vision.imageanalysis.models.VisualFeatures(str, Enum):\",\"suggestion\":\"class azure.ai.vision.imageanalysis.models.VisualFeatures(str, Enum, metaclass=CaseInsensitiveEnumMeta):\",\"comment\":\"Enums should accept case-insensitive values by using the CaseInsensitiveEnumMeta metaclass.\",\"source\":\"guideline\"}]}","testcase":"small_apiview_few_violations","context":"\nDO use a separate factory classmethod from_connection_string to create a client from a connection string (if the client supports connection strings). The from_connection_string factory method should take the same set of arguments (excluding information provided in the connection string) as the constructor. The constructor (__init__ method) must not take a connection string, even if it means that using the from_connection_string is the only supported method to create an instance of the client.\nDO NOT duplicate models between the root and aio namespace.","line_number":0}
