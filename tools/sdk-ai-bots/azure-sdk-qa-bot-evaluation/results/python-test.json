[
    {
        "testcase": "Python Live Test for async api",
        "expected": {
            "answer": "You're encountering an SSL certificate error when running live tests for async APIs, specifically when connecting to https://localhost:5001. This is the test proxy endpoint, and the error is likely due to certificate verification failing. Although the same code works for another team member, the issue may be caused by environment variables \u2014 either missing or incorrectly set.\nTo run live tests, make sure AZURE_TEST_RUN_LIVE is set to \"true\". If you also want to record, avoid setting AZURE_SKIP_LIVE_RECORDING. As a workaround for the SSL issue, set the environment variable PROXY_URL to http://localhost:5000 instead of using HTTPS. This bypasses certificate validation and resolves the issue.",
            "reference_urls": [
                "https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/test_proxy_troubleshooting.md",
                "https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/tests-advanced.md"
            ]
        },
        "actual": {
            "answer": "Your async Python live test is failing to connect to the test proxy on https://localhost:5001 due to an SSL certificate verification error. This is a known issue when the test proxy's self-signed certificate is not correctly configured or recognized by your Python environment, especially for async tests. \n\nTo resolve this:\n1. **Update your local repo**: Make sure you have the latest main branch from the Azure SDK for Python repo. The test proxy certificate is occasionally rotated, and the most recent version may fix your issue.\n2. **Try HTTP instead of HTTPS**: Unset the `PROXY_URL` environment variable or set it to `http://localhost:5000` to use the HTTP endpoint, which does not require SSL verification. This is the recommended workaround for async test environments that struggle with SSL certificate verification.\n   ```\n   # Windows CMD\n   set PROXY_URL=http://localhost:5000\n   # PowerShell\n   $env:PROXY_URL=\"http://localhost:5000\"\n   # Bash\n   export PROXY_URL=\"http://localhost:5000\"\n   ```\n3. **If HTTPS is required**: If your tests must use HTTPS and updating the repo does not resolve the issue, you may need to reach out to the Azure SDK team for support, as async environments can fail nondeterministically due to SSL verification issues.\n\nSummary: For most async Python live test scenarios, switching the test proxy to HTTP (`http://localhost:5000`) resolves certificate errors and allows your tests to run successfully.\n",
            "reference_urls": [
                "https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/test_proxy_troubleshooting.md",
                "https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/tests-advanced.md"
            ]
        },
        "similarity": 4.0,
        "gpt_similarity": 4.0,
        "similarity_result": "pass",
        "similarity_threshold": 4,
        "groundedness": 5.0,
        "gpt_groundedness": 5.0,
        "groundedness_reason": "The RESPONSE is fully grounded in the CONTEXT, accurately reflecting the troubleshooting steps and rationale provided in the source material, without adding unsupported details or missing key points.",
        "groundedness_result": "pass",
        "groundedness_threshold": 3.0,
        "response_completeness": 4.0,
        "response_completeness_result": "pass",
        "response_completeness_threshold": 3,
        "response_completeness_reason": "The Response is mostly complete, covering the main issue, the workaround, and additional advice, but misses some minor details about required environment variables for live tests and recording, and the environment variable cause.",
        "overall_score": 6.0
    },
    {
        "testcase": "release pipeline link for Python SDK `azure-mgmt-resource-bicep`",
        "expected": {
            "answer": "To find the specific release pipeline link for the Python SDK `azure-mgmt-resource-bicep`, you typically need to locate the corresponding pipeline in Azure DevOps under the internal Azure SDK project. The naming convention for the pipeline is usually `python - <servicedir>`, where `<servicedir>` matches the service directory (in this case, likely resource or resource-bicep).\nHere is the general process:\n1. Go to [Azure DevOps - Azure SDK Internal Project](https://dev.azure.com/azure-sdk/internal/_build)\n2. Search for the pipeline named `python - resource` or similar, as the pipeline is named according to the service directory for management SDKs.\n3. The direct link format for a service pipeline is: `https://dev.azure.com/azure-sdk/internal/_build?definitionId=<ID>&_a=summary`\n- You can search for `resource` in the pipelines list to locate the exact one.",
            "reference_urls": [
                "https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/release.md"
            ]
        },
        "actual": {
            "answer": "To find the release pipeline link for the Python SDK package `azure-mgmt-resource-bicep`, you should locate the appropriate pipeline in the Azure DevOps internal project, specifically under the Python language folder. The naming convention for service directory pipelines is `python - <servicedir>`. For the `azure-mgmt-resource-bicep` package, the service directory is typically `resource`.\n\nYou can access the full list of pipelines at: https://dev.azure.com/azure-sdk/internal/_build?view=pipelines&option=recent\n\nThe direct pipeline link for Python management SDKs for resource (which includes `azure-mgmt-resource-bicep`) is:\n\nhttps://dev.azure.com/azure-sdk/internal/_build?definitionId=1012\n\nOnce you open this link, you can queue builds, run release pipelines, and select the specific package (`azure-mgmt-resource-bicep`) for release as needed. Make sure you have appropriate access permissions.\n\nReference: The release process for Python SDKs involves locating the correct pipeline by service directory and using the unified pipelines for build and release. The link above is constructed based on standard conventions and available documentation.",
            "reference_urls": [
                "https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/release.md",
                "https://eng.ms/docs/products/azure-developer-experience/develop/sdk-release/sdk-release-pipeline"
            ]
        },
        "similarity": 5.0,
        "gpt_similarity": 5.0,
        "similarity_result": "pass",
        "similarity_threshold": 4,
        "groundedness": NaN,
        "gpt_groundedness": NaN,
        "groundedness_reason": "",
        "groundedness_result": "unknown",
        "groundedness_threshold": 3.0,
        "response_completeness": 4.0,
        "response_completeness_result": "pass",
        "response_completeness_threshold": 3,
        "response_completeness_reason": "The response contains all necessary information and instructions from the ground truth, with only a minor omission of the direct link format detail. It is otherwise fully complete.",
        "overall_score": 0.0
    },
    {
        "testcase": "Python SDK gen failing on relative tsp path",
        "expected": {
            "answer": "According to error log, it seems that your typespec refer to folder outside project folder but you don't declare it in `tspconfig.yaml`. You could add the missing dir like below then try again:\n```\n\"@azure-tools/typespec-client-generator-cli\":\nadditionalDirectories:\n- \"specification/keyvault/Security.KeyVault.Common/\"\n```",
            "reference_urls": []
        },
        "actual": {
            "answer": "Your SDK generation pipeline is failing due to unresolved relative TypeSpec imports such as \"../Discovery.Shared/namespace.tsp\". This is a common issue when the TypeSpec compiler or the pipeline does not know to sync or include shared directories that are referenced by relative imports.\n\nTo resolve this, you need to explicitly tell the TypeSpec compiler (and the pipeline) to include these shared directories using the `additionalDirectories` field in your `tspconfig.yaml`.\n\n**How to fix:**\n1. Open your `tspconfig.yaml` (usually found at the root of your TypeSpec project, e.g., `specification/discoverydev/Discovery.Workspace/tspconfig.yaml`).\n2. Add an `additionalDirectories` section, listing each relative path to the shared folders containing the imported `.tsp` files. Paths must be relative to the `tspconfig.yaml` location.\n\nExample:\n```yaml\ndirectory: specification/discoverydev/Discovery.Workspace\ncommit: <YOUR_COMMIT_SHA>\nrepo: Azure/azure-rest-api-specs\nadditionalDirectories:\n  - specification/discoverydev/Discovery.Shared\n```\n\nThis tells the pipeline to sync all files in the `Discovery.Shared` directory, allowing the compiler to resolve imports like `../Discovery.Shared/namespace.tsp`.\n\n**Next steps:**\n- Commit and push your updated `tspconfig.yaml`.\n- Re-run the pipeline or SDK generation workflow.\n- If you have multiple shared directories, list each one in the array.\n\n**Reference:**\n- The Azure REST API Specs wiki and TypeSpec Azure docs both state that unresolved import errors (\"import-not-found\") are almost always due to missing entries in `additionalDirectories`. See the linked documentation for more examples and troubleshooting guidance.",
            "reference_urls": [
                "https://github.com/Azure/azure-rest-api-specs/wiki/SDK-Validation",
                "https://azure.github.io/typespec-azure/docs/howtos/generate-with-tsp-client/local_spec_quickstart",
                "https://azure.github.io/typespec-azure/docs/howtos/generate-with-tsp-client/intro_tsp_client"
            ]
        },
        "similarity": 5.0,
        "gpt_similarity": 5.0,
        "similarity_result": "pass",
        "similarity_threshold": 4,
        "groundedness": NaN,
        "gpt_groundedness": NaN,
        "groundedness_reason": NaN,
        "groundedness_result": NaN,
        "groundedness_threshold": NaN,
        "response_completeness": 5.0,
        "response_completeness_result": "pass",
        "response_completeness_threshold": 3,
        "response_completeness_reason": "The response contains all the necessary and relevant information from the ground truth, accurately and thoroughly, with no missing statements or claims.",
        "overall_score": 0.0
    },
    {
        "testcase": "MS Learning Documentation Categorization as \"Unknown\"",
        "expected": {
            "answer": "Yes, to ensure the documentation for azure-ai-transcription appears under the \"cognitive-services\" category on Microsoft Learn, you need to add or update the metadata for this package in the metadata CSV file located at https://github.com/Azure/azure-sdk/blob/main/_data/releases/latest/python-packages.csv.\nSpecifically, you should:\n1. Find (or add) the row for azure-ai-transcription in python-packages.csv.\n2. Set the MSDocService field to \"cognitive-services\". This value is used to correctly categorize the package in the Learn docs hierarchy.\n3. Ensure other relevant fields (ServiceName, DisplayName, Type, etc.) are filled in appropriately.\nAfter updating the CSV, commit and create a PR in the azure-sdk repo. Once merged, the next docs build will pick up the new metadata and your package will be categorized correctly.\nIf the Notes field for your package is set to \"Needs Review\", update it to another value to avoid automation overwriting your changes.\nReferences and field details can be found here:\n- [CSV field README](https://github.com/Azure/azure-sdk/blob/main/eng/README.md#csv-fields)\n- [Relevant CSV file for Python packages](https://github.com/Azure/azure-sdk/blob/main/_data/releases/latest/python-packages.csv)\nIn summary: Yes, registering your package in the metadata CSV with MSDocService: cognitive-services is required. This action will resolve the warning and correct the Learn categorization.\n**References**\n[Publish SDK reference docs / Onboard a released package | Azure-sdk-docs-eng](https://eng.ms/docs/products/azure-developer-experience/develop/sdk-docs)\n[Metadata CSV update process for Python | Azure Sdk For Python Docs](https://github.com/Azure/azure-sdk-for-python/blob/main/doc/deprecation_process.md)",
            "reference_urls": []
        },
        "actual": {
            "answer": "Yes, to ensure your package documentation appears under the correct service category (e.g., cognitive-services) on Microsoft Learn, you must update the metadata CSV for Python packages (python-packages.csv) in the azure-sdk GitHub repo and set the MSDocService field to 'cognitive-services'.\n\nThe warning \"The service of package: cognitiveservices\" typically means the docs build system could not resolve the service category for your package, so it places it in the 'unknown' folder. The MSDocService field is specifically used to categorize documentation on Learn. You should:\n\n1. Edit the relevant entry for azure-ai-transcription in _data/releases/latest/python-packages.csv:\n   - Set MSDocService to cognitive-services\n   - Ensure ServiceName is also set to Cognitive Services (if applicable)\n2. Commit and create a PR to the azure-sdk repo.\n3. Once merged, the next docs build will categorize the docs correctly.\n\nReferences below confirm the need to update the MSDocService field and CSV for correct categorization, as well as provide the link to the taxonomy for valid values.",
            "reference_urls": [
                "https://eng.ms/docs/products/azure-developer-experience/develop/sdk-docs",
                "https://eng.ms/docs/products/azure-developer-experience/develop/sdk-docs",
                "https://github.com/Azure/azure-sdk-for-python/blob/main/doc/deprecation_process.md"
            ]
        },
        "similarity": 5.0,
        "gpt_similarity": 5.0,
        "similarity_result": "pass",
        "similarity_threshold": 4,
        "groundedness": NaN,
        "gpt_groundedness": NaN,
        "groundedness_reason": "",
        "groundedness_result": "unknown",
        "groundedness_threshold": 3.0,
        "response_completeness": 4.0,
        "response_completeness_result": "pass",
        "response_completeness_threshold": 3,
        "response_completeness_reason": "The Response includes all major steps and reasoning, but omits minor details about other fields and the Notes field, and does not provide direct reference links.",
        "overall_score": 0.0
    },
    {
        "testcase": "\"black\" job in pipeline fails, but when I run locally, the tool does not make any changes",
        "expected": {
            "answer": "The \"black\" job in the Azure SDK for Python pipeline can fail for reasons beyond just code formatting. Even if running \"black\" locally with the same version (24.4.0) does not produce changes, there are a few areas to check for a root cause:\n1. Run Black with the Same Arguments as the Pipeline:The pipeline runs \"black\" using tox with specific arguments. Make sure you are running locally in the same way. From the official guidance, run: `tox run -e black -c ../../../eng/tox/tox.ini --root . -- .` This ensures that the same config files, paths, and excludes are used. The pipeline may use a different configuration or target files that you are not formatting locally. Or you can tried the same command used by ci: `python -m azpysdk.main black --isolate sdk/ai/azure-ai-projects`.\n2. Check for Hidden Files or Config Differences: The pipeline uses the repository\u2019s configuration, including pyproject.toml and any exclude/include patterns. Local runs may inadvertently skip files due to local ignore files, environment differences, or working directory mismatches. Double-check that your local environment matches the CI context.\n3. Run `git status` or `git diff` to find out whether there are files already formatted but not pushed to the pr.\n4. Line Endings and Whitespace: Sometimes, black fails due to line ending differences (CRLF vs LF) or invisible whitespace issues that are not flagged locally. Make sure your files have consistent line endings (prefer LF in repo).\n5. Check the Pipeline Log for Specific Files: Review the pipeline's failure log closely to see which files are reported as needing formatting. Sometimes, it\u2019s a file outside your typical working set (such as generated code or test files).\n6. Reproduce in a Clean Environment: To eliminate local state issues, clone your repo in a fresh directory and re-run the pipeline\u2019s black command as above. If you confirm that running \"black\" via tox in a clean environment with the same version does not report changes, but the pipeline still fails, check for possible pipeline caching or artifact issues. Otherwise, use the pipeline log to identify exactly which file is causing the failure and focus on that file. Removing the check is not recommended; instead, focus on aligning your local runs with the pipeline invocation. If you continue to see unexplained failures, reach out in the Azure SDK language team channel with your findings and the specific pipeline log excerpt.",
            "reference_urls": []
        },
        "actual": {
            "answer": "The 'black' job in the Azure pipeline failing while local runs succeed\u2014despite using the same Black version (24.4.0)\u2014is a common CI/CD challenge. Here are the main reasons and steps to diagnose and fix the issue, based strictly on Azure Python SDK engineering system best practices:\n\n**Potential Causes:**\n1. **Environment Differences:**\n   - The pipeline may run Black with different settings, configuration files, or in a different working directory. For example, extra arguments, unexpected file paths, or a different Python environment may affect formatting.\n2. **Line Endings or File System Issues:**\n   - CI agents often use Linux, while local development might be on Windows or macOS. Black can be sensitive to line endings (LF vs CRLF) and file permissions.\n3. **Untracked or Uncommitted Files:**\n   - Sometimes, files present locally may be ignored or altered in the CI (e.g., .gitignore, unstaged changes).\n4. **Black Configuration Location:**\n   - Black reads configuration from pyproject.toml in the current directory. If the pipeline's working directory is different, it may not find the correct config, or might use a default.\n\n**How to Diagnose and Fix:**\n1. **Reproduce Pipeline Locally:**\n   - Run the exact pipeline command locally, including any arguments and using the repo's root directory. For Azure SDK Python, the official guidance is:\n     ```bash\n     tox run -e black -c ../../../eng/tox/tox.ini --root . -- .\n     ```\n     Replace `.` with your package path as needed. This matches the pipeline invocation (see reference below).\n2. **Check Pipeline Logs:**\n   - Review the pipeline logs for the full black command, paths being checked, and any files flagged as not properly formatted. This can help identify if the pipeline is formatting files you are not checking locally.\n3. **Line Endings:**\n   - Ensure all files have consistent LF line endings. You can use tools like `dos2unix` or `git config --global core.autocrlf input` to standardize.\n4. **Configuration Consistency:**\n   - Confirm that `pyproject.toml` is present at the correct location, and contains `[tool.azure-sdk-build] black = true`. Optionally, check for any other `[tool.black]` settings that may affect formatting.\n5. **Run Black With Arguments:**\n   - You can provide any arguments after the `--` in the tox command. For example, to format a specific file:\n     ```bash\n     tox run -e black -c ../../../eng/tox/tox.ini --root . -- path/to/file.py\n     ```\n\n**Summary:**\n- Do NOT remove the check; it's required for repo compliance.\n- Always use the pipeline's exact command and working directory when running locally.\n- Standardize line endings and verify configuration files.\n- Review pipeline logs to pinpoint files or arguments causing issues.\n\nIf the issue persists after these steps, please share the specific pipeline command and output. You can also refer to the official contributing guide for local build and test instructions.",
            "reference_urls": [
                "https://github.com/Azure/azure-sdk-for-python/blob/main/doc/eng_sys_checks.md",
                "https://github.com/Azure/azure-sdk-for-python/blob/main/doc/tool_usage_guide.md",
                "https://eng.ms/docs/products/azure-developer-experience/support/support",
                "https://eng.ms/docs/products/azure-developer-experience/support/troubleshoot/build-local"
            ]
        },
        "similarity": 5.0,
        "gpt_similarity": 5.0,
        "similarity_result": "pass",
        "similarity_threshold": 4,
        "groundedness": NaN,
        "gpt_groundedness": NaN,
        "groundedness_reason": NaN,
        "groundedness_result": NaN,
        "groundedness_threshold": NaN,
        "response_completeness": 4.0,
        "response_completeness_result": "pass",
        "response_completeness_threshold": 3,
        "response_completeness_reason": "The Response is mostly complete, covering nearly all key points from the Ground Truth, but omits a few minor details about clean environment reproduction, pipeline caching/artifacts, and escalation steps.",
        "overall_score": 0.0
    },
    {
        "testcase": "Ubunty 2303 pypy39 specific failure",
        "expected": {
            "answer": "You have a dependency that doesn't ship a pypy39 dep. That's all. You could swap that with pypy311 in your matrix if you wanted to give it a shot.",
            "reference_urls": []
        },
        "actual": {
            "answer": "The error message indicates that your Azure pipeline is attempting to build with PyPy 3.9, but the PyO3 library now requires PyPy >= 3.11. This means PyPy 3.9 is no longer supported by PyO3, and attempting to build with it will fail. To resolve this issue, you must upgrade your PyPy interpreter to at least version 3.11 in your pipeline configuration.\n\nActionable steps:\n1. Update your pipeline or environment configuration to use PyPy 3.11 (or higher) instead of PyPy 3.9.\n2. Ensure that your project and dependencies are compatible with PyPy 3.11.\n\nAdditionally, the Azure SDK for Python monorepo requires Python >= 3.9, but for Sphinx checks (and likely other dependencies moving forward), Python >= 3.11 is now required due to compatibility constraints with external processes. PyPy should follow similar minimum versioning to avoid such build failures.\n\nIf you continue to see issues after updating the PyPy version, review your pipeline logs for any additional errors and verify that all build steps are using the correct Python interpreter version.",
            "reference_urls": [
                "https://github.com/Azure/azure-sdk-for-python/blob/main/doc/tool_usage_guide.md"
            ]
        },
        "similarity": 4.0,
        "gpt_similarity": 4.0,
        "similarity_result": "pass",
        "similarity_threshold": 4,
        "groundedness": 3.0,
        "gpt_groundedness": 3.0,
        "groundedness_reason": "The RESPONSE is accurate regarding Python version requirements but adds unsupported details about PyPy and PyO3 that are not present in the CONTEXT.",
        "groundedness_result": "pass",
        "groundedness_threshold": 3.0,
        "response_completeness": 5.0,
        "response_completeness_result": "pass",
        "response_completeness_threshold": 3,
        "response_completeness_reason": "The response fully covers the ground truth's statements and provides additional helpful context, without omitting any necessary information.",
        "overall_score": 5.6
    },
    {
        "testcase": "Python emitter issue with bulleted list TypeSpec doc string, and other",
        "expected": {
            "answer": "The Sphinx docstring errors you're seeing in the generated Python SDK (unexpected indentation, block quote ends without a blank line, duplicate explicit target names, bullet/definition list issues) are caused by how TypeSpec documentation comments are emitted into Python docstrings, especially when those comments use Markdown or formatting that doesn't map cleanly to reStructuredText (reST), which Sphinx expects.\nTo resolve these errors, there are two possible solutions:\n1. You need to ensure that the TypeSpec doc comments for the Response model and ServiceTier union are written in a way that avoids problematic Markdown constructs and closely follows what Sphinx/reST expects.\nHere are practical steps:\n- **Bullet/Definition List Formatting:** - Avoid using Markdown bullet lists (`*`, `-`, or `+`) or definition lists in your TypeSpec doc comments. Instead, use plain sentences, or, if you need a list, format it as numbered items with clear line breaks between each item. - If you must use a list, add a blank line before and after the list, and ensure each item starts on a new line. Do not nest lists or use complex indentation.\n- **Inline Strong/Emphasis Markup:** - If you use `**bold**` or `*italic*` in TypeSpec comments, Sphinx may misinterpret these if not balanced. Prefer using plain text or ensure that every start marker has a matching end marker.\n- **Explicit Targets (Links):** - If you use `[Learn more](url)` in doc comments, emitting these into Python docstrings can result in duplicate explicit target names. Use plain URLs or avoid repeating the same anchor text multiple times.\n- **Block Quotes:** - Avoid using Markdown block quotes (`>`) in TypeSpec doc comments. If you need to highlight something, use plain sentences.\n- **Unexpected Indentation:** - Ensure all TypeSpec doc comments are left-aligned, with no leading spaces or tabs before the text, unless you are deliberately creating a code block. For code blocks, use triple backticks and add blank lines before and after the block.\n- **General Style:** - Write documentation in simple paragraphs. Do not mix Markdown with reST, and avoid complex formatting. - Example of a safe docstring for a model property: ```tsp /** * The list of available service tiers. Possible values include: * 1. Basic - Entry-level tier. * 2. Standard - Recommended for most workloads. * 3. Premium - Advanced tier for high throughput. */ ``` - Avoid: ```tsp /** * - Basic * - Standard * - Premium */ ``` **Actionable Steps:** - Go to your TypeSpec definitions for Response and ServiceTier, and revise any doc comments containing bullet lists, definition lists, block quotes, repeated anchor text, or excessive indentation. Replace with simple sentences or numbered lists as above. - After making these changes, regenerate the Python SDK and run the Sphinx build again. The warnings/errors should be resolved. - For reference on Python docstring formatting and Sphinx compatibility, see the Azure Python SDK [docstring guidelines](https://github.com/Azure/azure-sdk-for-python/blob/main/doc/dev/docstring.md). If you need a specific example for ServiceTier: ```tsp /** * Service tier for deployment. Possible values: * 1. Basic: Entry-level tier. * 2. Standard: Recommended tier. * 3. Premium: Advanced tier for large workloads. */ union ServiceTier { ... } ``` And for Response model, ensure any lists or references are in plain sentences and do not use block quotes or repeated links.\n2. Or you can disable the sphinx environment within the pyproject.toml for the problematic package. By that way you won't hit these sphinx failures.\n```\n[tool.azure-sdk-build]\nsphinx = false\n```",
            "reference_urls": []
        },
        "actual": {
            "answer": "To resolve the Sphinx/docutils warnings and errors in the generated Python SDK documentation (such as \"Inline strong start-string without end-string\", \"Duplicate explicit target name\", \"Unexpected indentation\", and issues with bullet lists), you need to update the TypeSpec docstrings and formatting in your TypeSpec definitions so they produce valid Python docstrings that are compatible with Sphinx and docutils. \n\nHere are concrete recommendations for your two problematic TypeSpec pieces:\n\n1. **Response model (docstring issues: block quotes, definition lists, indentation):**\n   - Ensure all TypeSpec doc comments use consistent indentation. For multi-line comments, each line should be prefixed with `///` and the content should be left-aligned (not indented).\n   - Avoid using reStructuredText (reST) formatting directly in TypeSpec docstrings unless you have validated the output. For lists, use a plain text style:\n     ```typescript\n     /// Output tools used:\n     /// - tool1: Description\n     /// - tool2: Description\n     ```\n   - Ensure a blank line separates block quotes or lists from other text to prevent \"unexpected unindent\" errors.\n   - Avoid definition lists (term followed by indented definition) as these can cause parsing issues in Python.\n   - Do not use explicit target links like `` `Learn More <url>`_ `` unless you ensure each target is unique and formatted as Sphinx expects.\n   - For any multi-line property documentation, use a single doc comment and keep it simple. For example:\n     ```typescript\n     /// Conversation object or null if not available.\n     conversation: { id: string; } | null;\n     ```\n\n2. **ServiceTier union (docstring issue: bullet list ends without blank line):**\n   - If you have a doc comment above the union or its members that includes a bullet list, make sure to:\n     - Start the list with a blank line before the first bullet.\n     - End the list with a blank line after the last bullet.\n     - Ensure no mixed indentation.\n     Example:\n     ```typescript\n     /// Service tier. Possible values:\n     ///\n     /// - auto: Automatic tier selection\n     /// - default: Default tier\n     /// - flex: Flexible tier\n     /// - scale: Scalable tier\n     /// - priority: Priority tier\n     ///\n     union ServiceTier {\n       \"auto\",\n       \"default\",\n       \"flex\",\n       \"scale\",\n       \"priority\",\n     }\n     ```\n\n**General Docstring Formatting Guidance for TypeSpec \u2192 Python SDK \u2192 Sphinx:**\n- Avoid indentation inside TypeSpec doc comments unless it is part of a code block.\n- For any multi-line description, use single doc comment blocks with blank lines between paragraphs and after lists.\n- Do not use explicit hyperlinks with duplicate target names.\n- If you need to use bullet lists, ensure there are blank lines before and after the list.\n- Always validate the generated Python docstrings (in the output .py files) and run Sphinx locally as described in the [Azure SDK for Python engineering system doc](https://github.com/Azure/azure-sdk-for-python/blob/main/doc/eng_sys_checks.md):\n  ```\n  tox run -e sphinx -c ../../../eng/tox/tox.ini --root .\n  ```\n\nIf you follow these formatting rules and update the doc comments for your Response model and ServiceTier union as shown above, the Sphinx/docutils warnings and errors should be eliminated.\n\n**Next Steps:**\n- Update your TypeSpec definitions as above.\n- Re-run `tsp-client update` and validate the generated Python code.\n- Run Sphinx locally to confirm the issues are resolved.\n- If any warnings remain, review the generated docstrings and adjust TypeSpec comments until all errors are gone.\n\nFor more details, see the [Sphinx/docstring checker section](https://github.com/Azure/azure-sdk-for-python/blob/main/doc/eng_sys_checks.md) in the Azure SDK for Python engineering system documentation.",
            "reference_urls": [
                "https://github.com/Azure/azure-sdk-for-python/blob/main/doc/eng_sys_checks.md"
            ]
        },
        "similarity": 4.0,
        "gpt_similarity": 4.0,
        "similarity_result": "pass",
        "similarity_threshold": 4,
        "groundedness": NaN,
        "gpt_groundedness": NaN,
        "groundedness_reason": NaN,
        "groundedness_result": NaN,
        "groundedness_threshold": NaN,
        "response_completeness": 4.0,
        "response_completeness_result": "pass",
        "response_completeness_threshold": 3,
        "response_completeness_reason": "The response is mostly complete, accurately reflecting the ground truth's main solution and guidance, but it misses the alternative workaround of disabling Sphinx in pyproject.toml.",
        "overall_score": 0.0
    },
    {
        "average_score": 1.657142857142857,
        "total_evals": 7,
        "similarity_pass_rate": 7,
        "groundedness_pass_rate": 2,
        "response_completeness_pass_rate": 7,
        "similarity_fail_rate": 0,
        "groundedness_fail_rate": 0,
        "response_completeness_fail_rate": 0
    }
]