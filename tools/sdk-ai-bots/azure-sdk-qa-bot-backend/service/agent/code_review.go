package agent

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"sort"
	"strings"
	"sync"

	"github.com/Azure/azure-sdk-for-go/sdk/ai/azopenai"
	"github.com/Azure/azure-sdk-for-go/sdk/azcore/to"
	"github.com/azure-sdk-tools/tools/sdk-ai-bots/azure-sdk-qa-bot-backend/config"
	"github.com/azure-sdk-tools/tools/sdk-ai-bots/azure-sdk-qa-bot-backend/model"
	"github.com/azure-sdk-tools/tools/sdk-ai-bots/azure-sdk-qa-bot-backend/service/prompt"
	"github.com/azure-sdk-tools/tools/sdk-ai-bots/azure-sdk-qa-bot-backend/service/search"
	"github.com/azure-sdk-tools/tools/sdk-ai-bots/azure-sdk-qa-bot-backend/utils"
	"github.com/google/uuid"
)

type CodeReviewService struct {
	searchClient *search.SearchClient
	promptParser prompt.DefaultPromptParser
}

// CodeReviewResponse represents the JSON response from the LLM
type CodeReviewResponse struct {
	Comments []model.ReviewComment `json:"comments"`
}

// CodeAnalysisQuery represents a single search query generated by the LLM
type CodeAnalysisQuery struct {
	Topic  string `json:"topic"`
	Query  string `json:"query"`
	Reason string `json:"reason"`
}

// CodeAnalysisResponse represents the LLM response for code analysis queries
type CodeAnalysisResponse struct {
	AnalysisSummary string              `json:"analysis_summary"`
	Queries         []CodeAnalysisQuery `json:"queries"`
}

const (
	maxGuidelineSnippets      = 8
	maxGuidelineContentLength = 4000
	maxResultsPerQuery        = 5
)

func NewCodeReviewService() (*CodeReviewService, error) {
	return &CodeReviewService{
		searchClient: search.NewSearchClient(),
		promptParser: prompt.DefaultPromptParser{},
	}, nil
}

func (s *CodeReviewService) Review(ctx context.Context, req *model.CodeReviewReq) (*model.CodeReviewResp, error) {
	if err := s.validateRequest(req); err != nil {
		return nil, err
	}

	requestID := uuid.New().String()
	log.SetPrefix(fmt.Sprintf("[RequestID: %s] ", requestID))

	jsonReq, err := json.Marshal(req)
	if err != nil {
		log.Printf("Failed to marshal request: %v\n", err)
	} else {
		log.Printf("Request: %s", utils.SanitizeForLog(string(jsonReq)))
	}

	guidelines, err := s.retrieveGuidelines(req.Language, req.FilePath, req.Code)
	if err != nil {
		log.Printf("[RequestID: %s] Failed to retrieve guidelines: %v", requestID, err)
		return nil, model.NewLLMServiceFailureError(fmt.Errorf("failed to retrieve guidelines: %w", err))
	}

	promptStr, err := s.buildCodeReviewPrompt(req, guidelines)
	if err != nil {
		log.Printf("[RequestID: %s] Failed to build prompt: %v", requestID, err)
		return nil, model.NewLLMServiceFailureError(fmt.Errorf("failed to build prompt: %w", err))
	}

	// debug: write prompt into a file
	_ = os.WriteFile("debug_prompt.prompty", []byte(promptStr), 0644)

	comments, err := getLLMReviewComments(ctx, promptStr, requestID)
	if err != nil {
		log.Printf("[RequestID: %s] Failed to get LLM review: %v", requestID, err)
		return nil, err
	}

	resp := &model.CodeReviewResp{
		ID:       requestID,
		Language: req.Language,
		Comments: comments,
	}

	if len(comments) > 0 {
		resp.Summary = fmt.Sprintf("Found %d potential issues or suggestions for improvement.", len(comments))
	} else {
		resp.Summary = "No guideline violations detected. Code looks good!"
	}

	log.Printf("[RequestID: %s] Code review completed with %d comments", requestID, len(comments))
	return resp, nil
}

func (s *CodeReviewService) validateRequest(req *model.CodeReviewReq) error {
	if req == nil {
		return model.NewInvalidRequestError("Request body is required", "")
	}
	if strings.TrimSpace(req.Language) == "" {
		return model.NewInvalidRequestError("Language is required", "")
	}
	if strings.TrimSpace(req.Code) == "" {
		return model.NewInvalidRequestError("Code is required", "")
	}
	return nil
}

func (s *CodeReviewService) retrieveGuidelines(language string, filePath string, code string) (string, error) {
	sources, sourceFilter := config.GetLanguageSources(language)

	// Use LLM to analyze code and generate targeted search queries
	queries, err := s.generateSearchQueries(context.Background(), language, filePath, code)
	if err != nil {
		return "", fmt.Errorf("failed to generate search queries: %w", err)
	}

	log.Printf("=== LLM Generated %d Search Queries ===", len(queries))
	for i, q := range queries {
		log.Printf("Query %d [%s]: %s (reason: %s)", i+1, q.Topic, q.Query, q.Reason)
	}

	// Step 2: Execute batch searches in parallel for all generated queries
	guidelineMap := make(map[string]model.Index)
	var mapMutex sync.Mutex
	var searchWg sync.WaitGroup

	for _, q := range queries {
		searchWg.Add(1)
		go func(query CodeAnalysisQuery) {
			defer searchWg.Done()
			if strings.TrimSpace(query.Query) == "" {
				return
			}
			results, err := s.searchClient.SearchTopKRelatedDocuments(query.Query, maxResultsPerQuery, sources, sourceFilter)
			if err != nil {
				log.Printf("Search failed for query '%s': %v", query.Query, err)
				return
			}

			mapMutex.Lock()
			for _, result := range results {
				key := buildGuidelineKey(result)
				if existing, ok := guidelineMap[key]; ok {
					if result.RerankScore > existing.RerankScore {
						guidelineMap[key] = result
					}
				} else {
					guidelineMap[key] = result
				}
			}
			mapMutex.Unlock()
		}(q)
	}

	searchWg.Wait()
	log.Printf("=== Total Unique Guidelines Found: %d ===", len(guidelineMap))

	// Step 3: Complete sections in parallel at header1 or header2 level to get full section content
	var completeWg sync.WaitGroup
	for key, result := range guidelineMap {
		if shouldCompleteSection(result) {
			completeWg.Add(1)
			go func(k string, r model.Index) {
				defer completeWg.Done()
				completed := s.searchClient.CompleteChunk(r)

				mapMutex.Lock()
				guidelineMap[k] = completed
				mapMutex.Unlock()
			}(key, result)
		}
	}

	completeWg.Wait()

	sorted := make([]model.Index, 0, len(guidelineMap))
	for _, result := range guidelineMap {
		sorted = append(sorted, result)
	}
	sort.Slice(sorted, func(i, j int) bool {
		if sorted[i].RerankScore == sorted[j].RerankScore {
			return sorted[i].Score > sorted[j].Score
		}
		return sorted[i].RerankScore > sorted[j].RerankScore
	})

	var guidelineTexts []string
	for _, result := range sorted {
		guidelineTexts = append(guidelineTexts, formatGuidelineSection(result))
		if len(guidelineTexts) >= maxGuidelineSnippets {
			break
		}
	}

	if len(guidelineTexts) == 0 {
		return "No specific guidelines found. Apply general SDK best practices.", nil
	}

	return joinWithSeparator(guidelineTexts, "\n---\n"), nil
}

// generateSearchQueries uses LLM to analyze code and generate targeted search queries
func (s *CodeReviewService) generateSearchQueries(ctx context.Context, language, filePath, code string) ([]CodeAnalysisQuery, error) {
	promptTemplate := "code_review/code_analysis_queries.md"

	params := map[string]string{
		"language":  language,
		"file_path": filePath,
		"content":   code,
	}

	promptStr, err := s.promptParser.ParsePrompt(params, promptTemplate)
	if err != nil {
		return nil, fmt.Errorf("failed to parse code analysis prompt template: %w", err)
	}

	messages := []azopenai.ChatRequestMessageClassification{
		&azopenai.ChatRequestSystemMessage{
			Content: azopenai.NewChatRequestSystemMessageContent(promptStr),
		},
	}

	resp, err := config.OpenAIClient.GetChatCompletions(ctx, azopenai.ChatCompletionsOptions{
		Messages:       messages,
		DeploymentName: to.Ptr(config.AppConfig.AOAI_CHAT_REASONING_MODEL),
		ResponseFormat: &azopenai.ChatCompletionsJSONResponseFormat{},
	}, nil)

	if err != nil {
		return nil, fmt.Errorf("failed to call LLM for query generation: %w", err)
	}

	if len(resp.Choices) == 0 {
		return nil, fmt.Errorf("no response from LLM")
	}

	content := *resp.Choices[0].Message.Content
	log.Printf("LLM code analysis response: %s", content)

	var analysisResp CodeAnalysisResponse
	if err := json.Unmarshal([]byte(content), &analysisResp); err != nil {
		return nil, fmt.Errorf("failed to parse LLM response: %w", err)
	}

	log.Printf("Code analysis summary: %s", analysisResp.AnalysisSummary)

	// Limit number of queries to prevent excessive API calls
	maxQueries := 8
	if len(analysisResp.Queries) > maxQueries {
		analysisResp.Queries = analysisResp.Queries[:maxQueries]
	}

	return analysisResp.Queries, nil
}

func (s *CodeReviewService) appendGuidelineResults(query string, sources []model.Source, sourceFilter map[model.Source]string, guidelineMap map[string]model.Index) error {
	if strings.TrimSpace(query) == "" {
		return nil
	}
	results, err := s.searchClient.SearchTopKRelatedDocuments(query, maxResultsPerQuery, sources, sourceFilter)
	if err != nil {
		return fmt.Errorf("failed to search guidelines: %w", err)
	}
	for _, result := range results {
		key := buildGuidelineKey(result)
		if existing, ok := guidelineMap[key]; ok {
			if result.RerankScore > existing.RerankScore {
				guidelineMap[key] = result
			}
			continue
		}
		guidelineMap[key] = result
	}
	return nil
}

func (s *CodeReviewService) buildCodeReviewPrompt(req *model.CodeReviewReq, guidelines string) (string, error) {
	promptTemplate := "code_review/sdk_code_review.md"

	params := map[string]string{
		"language":  req.Language,
		"file_path": req.FilePath,
		"context":   guidelines,
		"content":   req.Code,
	}

	promptStr, err := s.promptParser.ParsePrompt(params, promptTemplate)
	if err != nil {
		return "", fmt.Errorf("failed to parse prompt template: %w", err)
	}

	return promptStr, nil
}

func getLLMReviewComments(ctx context.Context, promptStr string, requestID string) ([]model.ReviewComment, error) {
	messages := []azopenai.ChatRequestMessageClassification{
		&azopenai.ChatRequestSystemMessage{
			Content: azopenai.NewChatRequestSystemMessageContent(promptStr),
		},
	}

	resp, err := config.OpenAIClient.GetChatCompletions(ctx, azopenai.ChatCompletionsOptions{
		Messages:       messages,
		DeploymentName: to.Ptr("gpt-5.1"),
		ResponseFormat: &azopenai.ChatCompletionsJSONResponseFormat{},
		// TopP:           to.Ptr(float32(config.AppConfig.AOAI_CHAT_COMPLETIONS_TOP_P)),
	}, nil)

	if err != nil {
		return nil, model.NewLLMServiceFailureError(fmt.Errorf("failed to call LLM: %w", err))
	}

	if len(resp.Choices) == 0 {
		return nil, model.NewLLMServiceFailureError(fmt.Errorf("no response from LLM"))
	}

	content := *resp.Choices[0].Message.Content
	log.Printf("[RequestID: %s] LLM response: %s", requestID, content)

	var reviewResp CodeReviewResponse
	if err := json.Unmarshal([]byte(content), &reviewResp); err != nil {
		return nil, model.NewLLMServiceFailureError(fmt.Errorf("failed to parse LLM response: %w", err))
	}

	return reviewResp.Comments, nil
}

func buildGuidelineKey(idx model.Index) string {
	if idx.ChunkID != "" {
		return idx.ChunkID
	}
	return fmt.Sprintf("%s|%s|%s|%s", idx.ContextID, idx.Title, idx.Header1, idx.Header2)
}

func formatGuidelineSection(original model.Index) string {
	guidelineParts := make([]string, 0, 4)
	if title := strings.TrimSpace(original.Title); title != "" {
		guidelineParts = append(guidelineParts, title)
	}
	for _, header := range []string{original.Header1, original.Header2, original.Header3} {
		if trimmed := strings.TrimSpace(header); trimmed != "" {
			guidelineParts = append(guidelineParts, trimmed)
		}
	}
	if len(guidelineParts) == 0 {
		guidelineParts = append(guidelineParts, firstNonEmpty(original.ContextID, original.ChunkID))
	}
	guidelineID := strings.Join(guidelineParts, "#")
	guidelineLink := model.GetIndexLink(original)

	var builder strings.Builder
	builder.WriteString(fmt.Sprintf("> **guideline_id:** %s<br>", guidelineID))
	builder.WriteString(fmt.Sprintf("> **guideline_link:** %s<br>", guidelineLink))
	builder.WriteString(fmt.Sprintf("> **source:** %s<br>", original.ContextID))
	builder.WriteString(fmt.Sprintf("> **score:** %.0f<br>\n", original.RerankScore*100))
	content := strings.TrimSpace(original.Chunk)
	truncated := truncateRunes(content, maxGuidelineContentLength)
	if len([]rune(content)) > maxGuidelineContentLength {
		truncated = strings.TrimSpace(truncated) + "..."
	}
	if truncated != "" {
		builder.WriteString(truncated)
		builder.WriteString("\n")
	}

	return builder.String()
}

func joinWithSeparator(items []string, separator string) string {
	result := ""
	for i, item := range items {
		result += item
		if i < len(items)-1 {
			result += separator
		}
	}
	return result
}

func truncateRunes(text string, limit int) string {
	if limit <= 0 {
		return ""
	}
	runes := []rune(text)
	if len(runes) <= limit {
		return text
	}
	return string(runes[:limit])
}

func firstNonEmpty(values ...string) string {
	for _, value := range values {
		if strings.TrimSpace(value) != "" {
			return value
		}
	}
	return ""
}

// shouldCompleteSection determines if a chunk should be completed to get full section content
func shouldCompleteSection(chunk model.Index) bool {
	// If there's no header3, this is likely a high-level section that should be completed
	return strings.TrimSpace(chunk.Header3) == ""
}
