# This script is intended for use in intermediate doc repos generated from docs.ms CI.
# Given a reference ToC and a set of namespaces, limit the reference to ToC entries that contain
# namespaces in our set.

import argparse
import pdb
import os
import fnmatch
import re
import json

# by default, yaml does not maintain insertion order of the dicts
# given that this is intended to generate TABLE OF CONTENTS values,
# maintaining this order is important.
# The drop-in replacement oyaml is a handy solution for us.
import oyaml as yaml


def filter_children(targeted_ns_list, known_namespaces):
    amended_list = []

    for ns in targeted_ns_list:
        # also need to handle when the namespace grep is a pattern
        # azure-eventhubs* <-- for instance
        if any(
            [
                re.match(fnmatch.translate(ns), known_namespace)
                for known_namespace in known_namespaces
            ]
        ):
            amended_list.append(ns)

    return amended_list

# the doc builds have the capability to reference readmes from external repos (they resolve during publishing)
# this means that we can't simply check the href values for existence. If they are an href that STARTS with one of the
# "dependent repositories" than we should leave them exactly as is.
# amend_href is the core of the logic for handling referenced files and ensures that we cannot refer to the same readme twice
# from two different reference ymls
def amend_href(toc_dict, repo_location, readme_suffix, excluded_href_paths):
    suffix = "-" + readme_suffix + ".md" if readme_suffix else  ".md"
    input_string = toc_dict["href"]

    # if this is an external readme, we should not attempt to resolve the file to a different one, just return with no changes
    if any([input_string.startswith(href) for href in excluded_href_paths]):
        return toc_dict 

    resolvable_path = os.path.join(repo_location, input_string.replace("~/", ""))
    possible_target_readme = os.path.splitext(resolvable_path)[0] + suffix

    if os.path.exists(possible_target_readme):
        toc_dict["href"] = input_string.replace(".md", suffix)
    else:
        toc_dict.pop("href")
        toc_dict["landingPageType"] = "Service"

    return toc_dict

# a post-order recursive function that returns a modified reference.yml
# based on the set of namespaces that we've grabbed from autogenerated ToC.yml
def filter_toc(toc_dict, namespaces, repo_location, readme_suffix="", excluded_href_paths = []):
    if toc_dict is None:
        return None

    # internal node
    if "items" in toc_dict:
        # recurse as mant times as necessary
        item_list = []
        for item in toc_dict["items"]:
            result_n = filter_toc(item, namespaces, repo_location, readme_suffix, excluded_href_paths)
            # only append the result if we know it exists
            if result_n:
                item_list.append(result_n)
        if item_list:
            toc_dict["items"] = item_list
        else:
            return None

    # handle href
    if "href" in toc_dict and repo_location:
        toc_dict = amend_href(toc_dict, repo_location, readme_suffix, excluded_href_paths)

    # leaf node
    if "children" in toc_dict:
        filtered_children = filter_children(toc_dict["children"], namespaces)
        # if we filter out all the children, this node should simply cease to exist
        if not filtered_children:
            return None

    # always amend the uid to include the suffix if one is present.
    if "uid" in toc_dict and readme_suffix:
        toc_dict["uid"] = toc_dict["uid"] + "." + readme_suffix

    return toc_dict

def grep_children_namespaces(autogenerated_toc_yml):
    return [
        top_level_namespace["name"] for top_level_namespace in autogenerated_toc_yml
    ] + ["*"]


# the doc builds have the capability to reference readmes from external repos (they resolve during publishing)
# this means that we can't simply check the href values for existence. If they are an href that STARTS with one of the
# "dependent repositories" than we should leave them exactly as is. This function returns the start paths
def get_non_standard_hrefs(doc_repo_location):
    excluded_href_paths = []

    target = os.path.join(doc_repo_location, ".openpublishing.publish.config.json")
    with open(target, "r") as f:
        data = json.load(f)

    for dependent_repo in data["dependent_repositories"]:
        excluded_href_paths.append("~/{}".format(dependent_repo["path_to_root"]))

    return excluded_href_paths

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="""
      Combines a reference and target ToC. The new target ToC mirrors the reference, omitting ToC
      entries that are NOT present in the preview output.
      """
    )

    parser.add_argument("-r", "--reference", help="The source ToC.yml", required=True)

    parser.add_argument("-t", "--target", help="The target ToC.yml", required=True)

    parser.add_argument(
        "-n",
        "--namespaces",
        help="The ToC.yml where target autogenerated documentation exists",
        required=True,
    )

    parser.add_argument(
        "-d",
        "--docrepo",
        help="The root directory of the target documentation repository.",
        required=True,
    )

    parser.add_argument(
        "-s",
        "--suffix",
        help="If possible, find readmes with this suffix.",
        default="",
        required=False,
    )

    args = parser.parse_args()

    try:
        with open(args.reference, "r") as reference_yml:
            base_reference_toc = yaml.safe_load(reference_yml)

        with open(args.namespaces, "r") as target_autogenerated_toc_yml:
            target_autogenerated_toc = yaml.safe_load(target_autogenerated_toc_yml)
    except Exception as f:
        print(
            "Execution requires that both the known namespaces and reference yml be defined."
        )

    present_in_target = grep_children_namespaces(target_autogenerated_toc)

    print(
        "Here are the visible namespaces in target autogenerated ToC. Constraining reference.yml."
    )
    for ns in sorted(present_in_target):
        print(" |__ " + ns)

    if args.docrepo:
        non_standard_paths = get_non_standard_hrefs(args.docrepo)
    else:
        non_standard_paths = []

    base_reference_toc[0] = filter_toc(
        base_reference_toc[0], present_in_target, args.docrepo, args.suffix, non_standard_paths
    )
    updated_content = yaml.dump(base_reference_toc, default_flow_style=False)

    with open(args.target, "w") as f:
        f.write(updated_content)
