{
   "testcase": "small_apiview_few_violations",
   "row": {
      "outputs.actual": "{\"comments\":[{\"guideline_ids\":[\"python_design.html#python-client-sync-async-separate-clients\"],\"memory_ids\":[],\"is_generic\":true,\"line_no\":53,\"bad_code\":\"class azure.ai.vision.imageanalysis.aio.ImageAnalysisClient(ImageAnalysisClient): implements AsyncContextManager\",\"suggestion\":\"class azure.ai.vision.imageanalysis.aio.ImageAnalysisClient(BaseImageAnalysisClient):\",\"comment\":\"The asynchronous client should be implemented independently from the synchronous client to maintain clear separation of sync and async behaviors. Avoid self-inheritance and the non-standard 'implements' clause; instead, inherit from a proper base client and use async context manager mixins as appropriate.\",\"correlation_id\":null,\"confidence_score\":1.0,\"severity\":\"SHOULD\"},{\"guideline_ids\":[\"python_implementation.html#python-codestyle-vars-naming\"],\"memory_ids\":[],\"is_generic\":true,\"line_no\":176,\"bad_code\":\"list: List[DenseCaption]\",\"suggestion\":\"captions: List[DenseCaption]\",\"comment\":\"Avoid using 'list' as a parameter name to prevent shadowing the built-in type. Use a more descriptive name like 'captions' to improve clarity and align with the attribute's purpose.\",\"correlation_id\":null,\"confidence_score\":1.0,\"severity\":\"SHOULD\"},{\"guideline_ids\":[],\"memory_ids\":[],\"is_generic\":true,\"line_no\":368,\"bad_code\":\"        list: List[DetectedObject]\",\"suggestion\":\"        objects: List[DetectedObject]\",\"comment\":\"Do not use the built‐in 'list' as a parameter name; 'objects' better conveys the content.\",\"correlation_id\":\"0be83051-3541-4ea1-ab45-6cb9ecc9e1bc\",\"confidence_score\":0.8,\"severity\":\"SHOULD\"},{\"guideline_ids\":[],\"memory_ids\":[],\"is_generic\":true,\"line_no\":408,\"bad_code\":\"        list: List[CropRegion]\",\"suggestion\":\"        regions: List[CropRegion]\",\"comment\":\"Avoid using 'list' to prevent shadowing the built‐in; choose a name like 'regions' to indicate crop regions.\",\"correlation_id\":\"0be83051-3541-4ea1-ab45-6cb9ecc9e1bc\",\"confidence_score\":0.8,\"severity\":\"SHOULD\"},{\"guideline_ids\":[],\"memory_ids\":[],\"is_generic\":true,\"line_no\":427,\"bad_code\":\"        list: List[DetectedTag]\",\"suggestion\":\"        tags: List[DetectedTag]\",\"comment\":\"Rename the parameter from 'list' to 'tags' to avoid overshadowing the built‐in and to align with the attribute name.\",\"correlation_id\":\"0be83051-3541-4ea1-ab45-6cb9ecc9e1bc\",\"confidence_score\":0.8,\"severity\":\"SHOULD\"}]}",
      "inputs.testcase": "small_apiview_few_violations",
      "inputs.query": "# Package is parsed using apiview-stub-generator(version:0.3.14), Python version: 3.12.9\n\nnamespace azure.ai.vision.imageanalysis\n\nclass azure.ai.vision.imageanalysis.ImageAnalysisClient(ImageAnalysisClient): implements ContextManager \n    def __init__(\n        self, \n        endpoint: str, \n        credential: Union[AzureKeyCredential, TokenCredential], \n        *, \n        api_version: str = ..., \n        **kwargs: Any\n    ) -> None\n\n    @distributed_trace\n    def analyze(\n        self, \n        image_data: bytes, \n        visual_features: List[VisualFeatures], \n        *, \n        gender_neutral_caption: Optional[bool] = ..., \n        language: Optional[str] = ..., \n        model_version: Optional[str] = ..., \n        smart_crops_aspect_ratios: Optional[List[float]] = ..., \n        **kwargs: Any\n    ) -> ImageAnalysisResult\n\n    @distributed_trace\n    def analyze_from_url(\n        self, \n        image_url: str, \n        visual_features: List[VisualFeatures], \n        *, \n        gender_neutral_caption: Optional[bool] = ..., \n        language: Optional[str] = ..., \n        model_version: Optional[str] = ..., \n        smart_crops_aspect_ratios: Optional[List[float]] = ..., \n        **kwargs: Any\n    ) -> ImageAnalysisResult\n\n    def close(self) -> None\n\n    def send_request(\n        self, \n        request: HttpRequest, \n        *, \n        stream: bool = False, \n        **kwargs: Any\n    ) -> HttpResponse\n\nnamespace azure.ai.vision.imageanalysis.aio\n\nclass azure.ai.vision.imageanalysis.aio.ImageAnalysisClient(ImageAnalysisClient): implements AsyncContextManager \n    def __init__(\n        self, \n        endpoint: str, \n        credential: Union[AzureKeyCredential, AsyncTokenCredential], \n        *, \n        api_version: str = ..., \n        **kwargs: Any\n    ) -> None\n\n    @distributed_trace_async\n    async def analyze(\n        self, \n        image_data: bytes, \n        visual_features: List[VisualFeatures], \n        *, \n        gender_neutral_caption: Optional[bool] = ..., \n        language: Optional[str] = ..., \n        model_version: Optional[str] = ..., \n        smart_crops_aspect_ratios: Optional[List[float]] = ..., \n        **kwargs: Any\n    ) -> ImageAnalysisResult\n\n    @distributed_trace_async\n    async def analyze_from_url(\n        self, \n        image_url: str, \n        visual_features: List[VisualFeatures], \n        *, \n        gender_neutral_caption: Optional[bool] = ..., \n        language: Optional[str] = ..., \n        model_version: Optional[str] = ..., \n        smart_crops_aspect_ratios: Optional[List[float]] = ..., \n        **kwargs: Any\n    ) -> ImageAnalysisResult\n\n    async def close(self) -> None\n\n    def send_request(\n        self, \n        request: HttpRequest, \n        *, \n        stream: bool = False, \n        **kwargs: Any\n    ) -> Awaitable[AsyncHttpResponse]\n\nnamespace azure.ai.vision.imageanalysis.models\n\nclass azure.ai.vision.imageanalysis.models.CaptionResult(MutableMapping[str, Any]):\n    ivar confidence: float\n    ivar text: str\n\n    @overload\n    def __init__(\n        self, \n        *, \n        confidence: float, \n        text: str\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nclass azure.ai.vision.imageanalysis.models.CropRegion(MutableMapping[str, Any]):\n    ivar aspect_ratio: float\n    ivar bounding_box: ImageBoundingBox\n\n    @overload\n    def __init__(\n        self, \n        *, \n        aspect_ratio: float, \n        bounding_box: ImageBoundingBox\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nnamespace azure.ai.vision.imageanalysis.models\n\nclass azure.ai.vision.imageanalysis.models.DenseCaption(MutableMapping[str, Any]):\n    ivar bounding_box: ImageBoundingBox\n    ivar confidence: float\n    ivar text: str\n\n    @overload\n    def __init__(\n        self, \n        *, \n        bounding_box: ImageBoundingBox, \n        confidence: float, \n        text: str\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.DenseCaptionsResult(MutableMapping[str, Any]):\n    ivar captions: List[DenseCaption]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        list: List[DenseCaption]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.DetectedTextBlock(MutableMapping[str, Any]):\n    ivar lines: List[DetectedTextLine]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        lines: List[DetectedTextLine]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nclass azure.ai.vision.imageanalysis.models.DetectedTextLine(MutableMapping[str, Any]):\n    ivar bounding_polygon: List[ImagePoint]\n    ivar text: str\n    ivar words: List[DetectedTextWord]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        bounding_polygon: List[ImagePoint], \n        text: str, \n        words: List[DetectedTextWord]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.DetectedTextWord(MutableMapping[str, Any]):\n    ivar bounding_polygon: List[ImagePoint]\n    ivar confidence: float\n    ivar text: str\n\n    @overload\n    def __init__(\n        self, \n        *, \n        bounding_polygon: List[ImagePoint], \n        confidence: float, \n        text: str\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.ImageAnalysisResult(MutableMapping[str, Any]):\n    ivar caption: Optional[CaptionResult]\n    ivar dense_captions: Optional[DenseCaptionsResult]\n    ivar metadata: ImageMetadata\n    ivar model_version: str\n    ivar objects: Optional[ObjectsResult]\n    ivar people: Optional[PeopleResult]\n    ivar read: Optional[ReadResult]\n    ivar smart_crops: Optional[SmartCropsResult]\n    ivar tags: Optional[TagsResult]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        caption: Optional[CaptionResult] = ..., \n        dense_captions: Optional[DenseCaptionsResult] = ..., \n        metadata: ImageMetadata, \n        model_version: str, \n        objects: Optional[ObjectsResult] = ..., \n        people: Optional[PeopleResult] = ..., \n        read: Optional[ReadResult] = ..., \n        smart_crops: Optional[SmartCropsResult] = ..., \n        tags: Optional[TagsResult] = ...\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.ImageBoundingBox(MutableMapping[str, Any]):\n    ivar height: int\n    ivar width: int\n    ivar x: int\n    ivar y: int\n\n    @overload\n    def __init__(\n        self, \n        *, \n        height: int, \n        width: int, \n        x: int, \n        y: int\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nclass azure.ai.vision.imageanalysis.models.ImageMetadata(MutableMapping[str, Any]):\n    ivar height: int\n    ivar width: int\n\n    @overload\n    def __init__(\n        self, \n        *, \n        height: int, \n        width: int\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.ImagePoint(MutableMapping[str, Any]):\n    ivar x: int\n    ivar y: int\n\n    @overload\n    def __init__(\n        self, \n        *, \n        x: int, \n        y: int\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.ObjectsResult(MutableMapping[str, Any]):\n    ivar list: List[DetectedObject]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        list: List[DetectedObject]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.ReadResult(MutableMapping[str, Any]):\n    ivar blocks: List[DetectedTextBlock]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        blocks: List[DetectedTextBlock]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\n\nclass azure.ai.vision.imageanalysis.models.SmartCropsResult(MutableMapping[str, Any]):\n    ivar list: List[CropRegion]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        list: List[CropRegion]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nclass azure.ai.vision.imageanalysis.models.TagsResult(MutableMapping[str, Any]):\n    ivar list: List[DetectedTag]\n\n    @overload\n    def __init__(\n        self, \n        *, \n        list: List[DetectedTag]\n    )\n\n    @overload\n    def __init__(self, mapping: Mapping[str, Any])\n\n    def __init__(\n        self, \n        *args: Any, \n        **kwargs: Any\n    ) -> None\n\nclass azure.ai.vision.imageanalysis.models.VisualFeatures(str, Enum):\n    CAPTION = 'caption'\n    DENSE_CAPTIONS = 'denseCaptions'\n    OBJECTS = 'objects'\n    PEOPLE = 'people'\n    READ = 'read'\n    SMART_CROPS = 'smartCrops'\n    TAGS = 'tags'",
      "inputs.language": "python",
      "inputs.context": "\nDO use a separate factory classmethod from_connection_string to create a client from a connection string (if the client supports connection strings). The from_connection_string factory method should take the same set of arguments (excluding information provided in the connection string) as the constructor. The constructor (__init__ method) must not take a connection string, even if it means that using the from_connection_string is the only supported method to create an instance of the client.\nDO NOT duplicate models between the root and aio namespace.",
      "inputs.response": {
         "comments": [
            {
               "guideline_ids": [
                  "python_design.html#python-client-connection-string"
               ],
               "line_no": 10,
               "bad_code": "connection_string: Optional[str] = None,",
               "suggestion": "Remove the connection_string parameter from the __init__ method and instead implement a separate from_connection_string class method.",
               "comment": "The constructor should not accept a connection string per the guideline. Instead, a factory method (from_connection_string) must be provided if supported.",
               "source": "guideline"
            },
            {
               "guideline_ids": [],
               "line_no": 171,
               "bad_code": "ivar list: List[DenseCaption]",
               "suggestion": "ivar captions: List[DenseCaption]",
               "comment": "Using 'list' as an attribute name shadows the built-in list type and may be ambiguous. A more descriptive name such as 'captions' would better convey its intent.",
               "source": "generic"
            },
            {
               "guideline_ids": [
                  "python_design.html#python-models-async"
               ],
               "line_no": 382,
               "bad_code": "class azure.ai.vision.imageanalysis.models.aio.PeopleResult(MutableMapping[str, Any]):",
               "suggestion": "Remove PeopleResult from the aio sub-namespace and define it only once in the shared models namespace.",
               "comment": "Models should not be duplicated between the root and aio namespace per the guidelines. Reuse the model from azure.ai.vision.imageanalysis.models.",
               "source": "guideline"
            }
         ]
      },
      "outputs.metrics.expected_comments": 2,
      "outputs.metrics.comments_found": 5,
      "outputs.metrics.true_positives": 0,
      "outputs.metrics.valid_generic_comments": 0,
      "outputs.metrics.invalid_generic_comments": 0,
      "outputs.metrics.false_positives": 5,
      "outputs.metrics.false_negatives": 2,
      "outputs.metrics.percent_coverage": 0,
      "outputs.metrics.rule_matches_wrong_line": 0,
      "outputs.metrics.wrong_line_details": [],
      "outputs.metrics.fuzzy_matches": 0,
      "outputs.metrics.groundedness": 1,
      "outputs.metrics.groundedness_reason": "The RESPONSE is not grounded in the CONTEXT, as it does not address or reflect the specific instructions provided. It introduces unrelated suggestions and does not mention the factory method, constructor, or model duplication rules.",
      "outputs.metrics.similarity": 1,
      "outputs.metrics.testcase": "small_apiview_few_violations",
      "outputs.metrics.score": 0
   }
}