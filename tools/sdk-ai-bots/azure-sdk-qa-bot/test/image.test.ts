import { describe, it, expect, vi, beforeEach, afterEach } from "vitest";
import { ImageInputProcessor } from "../src/input/ImageInputProcessor.js";
import { dirname, join } from "node:path";
import { fileURLToPath } from "url";
import { ComputerVisionClient } from "@azure/cognitiveservices-computervision";
import { ApiKeyCredentials } from "@azure/ms-rest-js";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

describe("Image OCR", () => {
    // it("should extract text from image", async () => {
    //     const imageProcessor = new ImageInputProcessor({
    //         languages: ["eng"],
    //         numWorkers: 1,
    //     });
    //     await imageProcessor.init();
    //     const imagePath = join(__dirname, "images/ocr-eng.png");
    //     const results = await imageProcessor.recognize([imagePath]);
    //     console.log("ğŸš€ ~ it ~ results:", results);
    //     expect(results[0].text).toBe(
    //         "Debugger listening on ws://127.0.8.1:9239/9d83219c-0d2e-40e9-a990-e9bde4d586a8\n" +
    //             "For help, see: https://nodejs.org/en/docs/inspector\n" +
    //             "\n" +
    //             "Debugger attached.\n" +
    //             "\n" +
    //             "Debugger attached.\n" +
    //             "\n" +
    //             "Bot Started, app listening to { address: '::'. family: 'IPv6'. port: 3978 }\n"
    //     );
    // });

    it("is a test", async () => {
        async function ocrWithTypeScript() {
            // 1. å¡«å…¥ä½ çš„ç»ˆç»“ç‚¹ï¼ˆendpointï¼‰å’Œå¯†é’¥ï¼ˆkeyï¼‰
            const endpoint =
                "https://wanl-test-ocr.cognitiveservices.azure.com/";
            // TODO: !!!!!!!!!!!!!!!!!!!!!!!!! dont upload this to github !!!!!!!!!!!!!!!!!!!!!!!!!!!
            const key = "xxxxxxxxxxxxxxxxxxxxxxxxx";

            // 2. åˆ›å»ºå®¢æˆ·ç«¯
            const creds = new ApiKeyCredentials({
                inHeader: { "Ocp-Apim-Subscription-Key": key },
            });
            const client = new ComputerVisionClient(creds, endpoint);

            // 3. æŒ‡å®šå¾… OCR çš„å›¾ç‰‡ URL
            const imageUrl =
                // "https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/printed_text.jpg";
                join(__dirname, "images/ocr-eng.png");

            const readResponse = await client.read(imageUrl);
            const operationLocation = readResponse.operationLocation;
            if (!operationLocation) {
                throw new Error(
                    "æœªèƒ½è·å– Operation-Locationï¼Œè¯·æ£€æŸ¥è¯·æ±‚æ˜¯å¦æ­£ç¡®ã€‚"
                );
            }
            const operationId = operationLocation.split("/").slice(-1)[0];

            // 5. è½®è¯¢ç›´åˆ°è¯†åˆ«å®Œæˆ
            let result;
            while (true) {
                result = await client.getReadResult(operationId);
                if (
                    result.status !== "notStarted" &&
                    result.status !== "running"
                ) {
                    break;
                }
                await new Promise((resolve) => setTimeout(resolve, 1000));
            }
            console.log("ğŸš€ ~ ocrWithTypeScript ~ result:", result);

            // 6. å¤„ç†å¹¶æ‰“å°è¯†åˆ«ç»“æœ
            if (
                result.status === "succeeded" &&
                result.analyzeResult?.readResults
            ) {
                for (const page of result.analyzeResult.readResults) {
                    console.log(`--- ç¬¬ ${page.page} é¡µ ---`);
                    for (const line of page.lines) {
                        console.log(line.text);
                    }
                }
            } else {
                console.error("OCR è¯†åˆ«æœªæˆåŠŸï¼Œè¯·æ£€æŸ¥è¾“å…¥å’Œå¯†é’¥ã€‚");
            }
        }

        await ocrWithTypeScript();
    });
});
